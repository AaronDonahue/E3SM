!>
!! @file
!! $Revision$
!! $LastChangedDate$
!! @brief SPMD helper routines
!<
#define __PIO_FILE__ "pio_spmd_utils.F90"
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!
!  Module pio_spmd_utils
!
!  Point-to-point implementations of
!  MPI collectives, for improved performance
!  and/or robustness on certain platforms
!
!
!  20090508  Initial version (based on spmd_utils in CAM) - P. Worley
!
! Code added as a work around for poor rsend performance on cray systems with
! Gemini interconnect
!
#ifdef _NO_MPI_RSEND
#define MPI_RSEND MPI_SEND
#define mpi_rsend mpi_send
#define MPI_IRSEND MPI_ISEND
#define mpi_irsend mpi_isend
#endif

module pio_spmd_utils

  use pio_kinds
  use pio_support, only: CheckMPIReturn
#ifndef NO_MPIMOD
  use mpi ! _EXTERNAL
#endif
  implicit none

  private
#ifdef NO_MPIMOD
  include 'mpif.h'  ! _EXTERNAL
#endif

  public :: pio_swapm, pio_N2M

  interface pio_swapm
     ! TYPE int,real,double,long
     module procedure pio_swapm_{TYPE}
  end interface

  interface pio_N2M
     ! TYPE int,real,double,long
     module procedure pio_N2M_{TYPE}
  end interface

  character(len=*), parameter :: modName='pio_spmd_utils'

contains
!========================================================================
!

   integer function pair(np,p,k)

      integer np,p,k,q
      q = ieor(p,k)
      if(q.gt.np-1) then
         pair = -1
      else
         pair = q
      endif
      return

   end function pair

!
!========================================================================
!

  integer function ceil2(n)
     integer n,p
     p=1
     do while(p.lt.n)
        p=p*2
     enddo
     ceil2=p
     return
  end function ceil2

!
!========================================================================
!
! TYPE int,real,double,long
   subroutine pio_swapm_{TYPE} ( nprocs, mytask,   &
      sndbuf, sbuf_siz, sndlths, sdispls, stypes,  &
      rcvbuf, rbuf_siz, rcvlths, rdispls, rtypes,  &
      comm, comm_hs, comm_isend, comm_maxreq       )

!-----------------------------------------------------------------------
!
!> Purpose:
!!   Reduced version of original swapm (for swap of multiple messages
!!   using MPI point-to-point routines), more efficiently implementing a
!!   subset of the swap protocols.
!!
!! Method:
!! comm_protocol:
!!  comm_isend == .true.: use nonblocking send, else use blocking send
!!  comm_hs == .true.: use handshaking protocol
!! comm_maxreq:
!!  =-1,0: do not limit number of outstanding send/receive requests
!!     >0: do not allow more than min(comm_maxreq, steps) outstanding
!!         nonblocking send requests or nonblocking receive requests
!!
!! Author of original version:  P. Worley
!! Ported from CAM: P. Worley, May 2009
!<
!-----------------------------------------------------------------------
#ifdef TIMING
  use perf_mod, only : t_startf, t_stopf   ! _EXTERNAL
#endif
!-----------------------------------------------------------------------
   implicit none
!---------------------------Input arguments--------------------------
!
   integer, intent(in)   :: nprocs             ! size of communicator
   integer, intent(in)   :: mytask             ! MPI task id with communicator
   integer, intent(in)   :: sbuf_siz           ! size of send buffer
   integer, intent(in)   :: rbuf_siz           ! size of receive buffer

   integer, intent(in)   :: sndlths(0:nprocs-1)! length of outgoing message
   integer, intent(in)   :: sdispls(0:nprocs-1)! offset from beginning of send
                                               !  buffer where outgoing messages
                                               !  should be sent from
   integer, intent(in)   :: stypes(0:nprocs-1) ! MPI data types
   integer, intent(in)   :: rcvlths(0:nprocs-1)! length of incoming messages
   integer, intent(in)   :: rdispls(0:nprocs-1)! offset from beginning of receive
                                               !  buffer where incoming messages
                                               !  should be placed
   integer, intent(in)   :: rtypes(0:nprocs-1) ! MPI data types
   {VTYPE}, intent(in)   :: sndbuf(sbuf_siz)   ! outgoing message buffer

   integer, intent(in)   :: comm               ! MPI communicator
   logical, intent(in)   :: comm_hs            ! handshaking protocol?
   logical, intent(in)   :: comm_isend         ! nonblocking send protocol?
   integer, intent(in)   :: comm_maxreq        ! maximum number of outstanding
                                               !  nonblocking requests

!---------------------------Output arguments--------------------------
!
   {VTYPE}, intent(out)  :: rcvbuf(rbuf_siz)   ! incoming message buffer

#ifndef _MPISERIAL
!
!---------------------------Local workspace-------------------------------------------
!
   character(len=*), parameter :: subName=modName//'::pio_swapm_{TYPE}'

   integer :: steps                            ! number of swaps to initiate
   integer :: swapids(nprocs)                  ! MPI process id of swap partners
   integer :: p                                ! process index
   integer :: istep                            ! loop index
   integer :: tag                              ! MPI message tag
   integer :: offset_t                         ! MPI message tag offset, for addressing
                                               !  message conflict bug (if necessary)
   integer :: offset_s                         ! index of message beginning in
                                               !  send buffer
   integer :: offset_r                         ! index of message beginning in
                                               !  receive buffer
   integer :: sndids(nprocs)                   ! send request ids
   integer :: rcvids(nprocs)                   ! receive request ids
   integer :: hs_rcvids(nprocs)                ! handshake receive request ids

   integer :: maxreq, maxreqh                  ! maximum number of outstanding
                                               !  nonblocking requests (and half)
   integer :: hs                               ! handshake variable
   integer :: rstep                            ! "receive" step index

   logical :: handshake, sendd                 ! protocol option flags

   integer :: ier                              ! return error status
   integer :: status(MPI_STATUS_SIZE)          ! MPI status
!
!-------------------------------------------------------------------------------------
!
#ifdef _NO_PIO_SWAPM_TAG_OFFSET
   offset_t = 0
#else
   offset_t = nprocs
#endif
!
   ! if necessary, send to self
   if (sndlths(mytask) > 0) then
      tag = mytask + offset_t

      offset_r = rdispls(mytask)+1
      call mpi_irecv( rcvbuf(offset_r), rcvlths(mytask), rtypes(mytask), &
                      mytask, tag, comm, rcvids(1), ier )
      call CheckMPIReturn(subName,ier)

      offset_s = sdispls(mytask)+1
      call mpi_send( sndbuf(offset_s), sndlths(mytask), stypes(mytask), &
                     mytask, tag, comm, ier )
      call CheckMPIReturn(subName,ier)

      call mpi_wait( rcvids(1), status, ier )
      call CheckMPIReturn(subName,ier)
   endif

   ! calculate swap partners and communication ordering
   steps = 0
   do istep=1,ceil2(nprocs)-1
      p = pair(nprocs,istep,mytask)
      if (p >= 0) then
         if (sndlths(p) > 0 .or. rcvlths(p) > 0) then
            steps = steps + 1
            swapids(steps) = p
         end if
      end if
   end do

   if (steps .eq. 0) return

   ! identify communication protocol
   if (comm_isend) then
      sendd = .false.
   else
      sendd = .true.
   endif
   handshake = comm_hs

   ! identify maximum number of outstanding nonblocking requests to permit
   if (steps .eq. 1) then
      maxreq  = 1
      maxreqh = 1
   else
      if (comm_maxreq >= -1) then
         maxreq = comm_maxreq
      else
         maxreq = steps
      endif

      if ((maxreq .le. steps) .and. (maxreq > 0)) then
         if (maxreq > 1) then
            maxreqh = maxreq/2
         else
            maxreq  = 2
            maxreqh = 1
         endif
      else
         maxreq  = steps
         maxreqh = steps
      endif
   endif

! Four protocol options:
!  (1) handshaking + blocking sends
   if ((handshake) .and. (sendd)) then

      ! Initialize hs variable
      hs = 1

      ! Post initial handshake receive requests
      do istep=1,maxreq
         p = swapids(istep)
         if (sndlths(p) > 0) then
            tag = mytask + offset_t
            call mpi_irecv( hs, 1, MPI_INTEGER, p, tag, comm, &
                            hs_rcvids(istep), ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo

      ! Post initial receive requests
      do istep=1,maxreq
         p = swapids(istep)
         if (rcvlths(p) > 0) then
            tag = p + offset_t

            offset_r = rdispls(p)+1
            call mpi_irecv( rcvbuf(offset_r), rcvlths(p), rtypes(p), &
                            p, tag, comm, rcvids(istep), ier )
            call CheckMPIReturn(subName,ier)

            call mpi_send ( hs, 1, MPI_INTEGER, p, tag, comm, ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo
      rstep = maxreq

      ! Send (and start receiving) data
      do istep=1,steps
         p = swapids(istep)

         ! Submit new rsend request
         if (sndlths(p) > 0) then
            tag = mytask + offset_t

            offset_s = sdispls(p)+1
            call mpi_wait  ( hs_rcvids(istep), status, ier )
            call CheckMPIReturn(subName,ier)

            call mpi_rsend ( sndbuf(offset_s), sndlths(p), stypes(p), &
                             p, tag, comm, ier )
            call CheckMPIReturn(subName,ier)
         endif

         if (istep > maxreqh) then

            ! Wait for oldest irecv request to complete
            p = swapids(istep-maxreqh)
            if (rcvlths(p) > 0) then
               call mpi_wait( rcvids(istep-maxreqh), status, ier )
               call CheckMPIReturn(subName,ier)
            endif

            if (rstep < steps) then
               rstep = rstep + 1
               p = swapids(rstep)

               ! Submit a new handshake irecv request
               if (sndlths(p) > 0) then
                  tag = mytask + offset_t
                  call mpi_irecv( hs, 1, MPI_INTEGER, p, tag, comm, &
                                  hs_rcvids(rstep), ier )
                  call CheckMPIReturn(subName,ier)
               endif

               ! Submit a new irecv request
               if (rcvlths(p) > 0) then
                  tag = p + offset_t

                  offset_r = rdispls(p)+1
                  call mpi_irecv( rcvbuf(offset_r), rcvlths(p), rtypes(p), &
                                  p, tag, comm, rcvids(rstep), ier )
                  call CheckMPIReturn(subName,ier)

                  call mpi_send ( hs, 1, MPI_INTEGER, p, tag, comm, ier )
                  call CheckMPIReturn(subName,ier)
               endif
            endif

         endif
!
      enddo

      ! wait for rest of receive requests to complete
      do istep=steps-maxreqh+1,steps
         p = swapids(istep)
         if (rcvlths(p) > 0) then
            call mpi_wait( rcvids(istep), status, ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo

!  (2) handshaking + nonblocking sends
   elseif ((handshake) .and. (.not. sendd)) then

      ! Initialize hs variable
      hs = 1

      ! Post initial handshake receive requests
      do istep=1,maxreq
         p = swapids(istep)
         if (sndlths(p) > 0) then
            tag = mytask + offset_t
            call mpi_irecv( hs, 1, MPI_INTEGER, p, tag, comm, &
                            hs_rcvids(istep), ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo

      ! Post initial receive requests
      do istep=1,maxreq
         p = swapids(istep)
         if (rcvlths(p) > 0) then
            tag = p + offset_t

            offset_r = rdispls(p)+1
            call mpi_irecv( rcvbuf(offset_r), rcvlths(p), rtypes(p), &
                            p, tag, comm, rcvids(istep), ier )
            call CheckMPIReturn(subName,ier)

            call mpi_send ( hs, 1, MPI_INTEGER, p, tag, comm, ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo
      rstep = maxreq

      ! Send (and start receiving) data
      do istep=1,steps
         p = swapids(istep)

         ! Submit new irsend request
         if (sndlths(p) > 0) then
            tag = mytask + offset_t

            offset_s = sdispls(p)+1
            call mpi_wait  ( hs_rcvids(istep), status, ier )
            call CheckMPIReturn(subName,ier)

            call mpi_irsend( sndbuf(offset_s), sndlths(p), stypes(p), &
                             p, tag, comm, sndids(istep), ier )
            call CheckMPIReturn(subName,ier)
         endif

         if (istep > maxreqh) then

            ! Wait for oldest irecv request to complete
            p = swapids(istep-maxreqh)
            if (rcvlths(p) > 0) then
               call mpi_wait( rcvids(istep-maxreqh), status, ier )
               call CheckMPIReturn(subName,ier)
            endif

            if (rstep < steps) then
               rstep = rstep + 1
               p = swapids(rstep)

               ! Submit a new handshake irecv request
               if (sndlths(p) > 0) then
                  tag = mytask + offset_t
                  call mpi_irecv( hs, 1, MPI_INTEGER, p, tag, comm, &
                                  hs_rcvids(rstep), ier )
                  call CheckMPIReturn(subName,ier)
               endif

               ! Submit a new irecv request
               if (rcvlths(p) > 0) then
                  tag = p + offset_t

                  offset_r = rdispls(p)+1
                  call mpi_irecv( rcvbuf(offset_r), rcvlths(p), rtypes(p), &
                                  p, tag, comm, rcvids(rstep), ier )
                  call CheckMPIReturn(subName,ier)

                  call mpi_send ( hs, 1, MPI_INTEGER, p, tag, comm, ier )
                  call CheckMPIReturn(subName,ier)
               endif
            endif

            ! Wait for outstanding i(r)send request to complete
            p = swapids(istep-maxreqh)
            if (sndlths(p) > 0) then
               call mpi_wait( sndids(istep-maxreqh), status, ier )
               call CheckMPIReturn(subName,ier)
            endif

         endif

      enddo

      ! wait for rest of send and receive requests to complete
      do istep=steps-maxreqh+1,steps
         p = swapids(istep)
         if (rcvlths(p) > 0) then
            call mpi_wait( rcvids(istep), status, ier )
            call CheckMPIReturn(subName,ier)
         endif
         if (sndlths(p) > 0) then
            call mpi_wait( sndids(istep), status, ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo

!  (3) no handshaking + blocking sends
   elseif ((.not. handshake) .and. (sendd)) then

      ! Post receive requests
      do istep=1,maxreq
         p = swapids(istep)
         if (rcvlths(p) > 0) then
            tag = p + offset_t

            offset_r = rdispls(p)+1
            call mpi_irecv( rcvbuf(offset_r), rcvlths(p), rtypes(p), &
                            p, tag, comm, rcvids(istep), ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo
      rstep = maxreq

      ! Send (and start receiving) data
      do istep=1,steps
         p = swapids(istep)

         ! Submit new send request
         if (sndlths(p) > 0) then
            tag = mytask + offset_t

            offset_s = sdispls(p)+1
            call mpi_send( sndbuf(offset_s), sndlths(p), stypes(p), &
                           p, tag, comm, ier )
            call CheckMPIReturn(subName,ier)
         endif

         if (istep > maxreqh) then

            ! Wait for oldest irecv request to complete
            p = swapids(istep-maxreqh)
            if (rcvlths(p) > 0) then
               call mpi_wait( rcvids(istep-maxreqh), status, ier )
               call CheckMPIReturn(subName,ier)
            endif

            ! Submit a new irecv request
            if (rstep < steps) then
               rstep = rstep + 1
               p = swapids(rstep)
               if (rcvlths(p) > 0) then
                  tag = p + offset_t

                  offset_r = rdispls(p)+1
                  call mpi_irecv( rcvbuf(offset_r), rcvlths(p), rtypes(p), &
                                  p, tag, comm, rcvids(rstep), ier )
                  call CheckMPIReturn(subName,ier)
               endif
            endif

         endif

      enddo

      ! wait for rest of send and receive requests to complete
      do istep=steps-maxreqh+1,steps
         p = swapids(istep)
         if (rcvlths(p) > 0) then
            call mpi_wait( rcvids(istep), status, ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo

!  (4) no handshaking + nonblocking sends
   elseif ((.not. handshake) .and. (.not. sendd)) then

      ! Post receive requests
      do istep=1,maxreq
         p = swapids(istep)
         if (rcvlths(p) > 0) then
            tag = p + offset_t

            offset_r = rdispls(p)+1
            call mpi_irecv( rcvbuf(offset_r), rcvlths(p), rtypes(p), &
                            p, tag, comm, rcvids(istep), ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo
      rstep = maxreq

      ! Send (and start receiving) data
      do istep=1,steps
         p = swapids(istep)

         ! Submit new isend request
         if (sndlths(p) > 0) then
            tag = mytask + offset_t

            offset_s = sdispls(p)+1
            call mpi_isend( sndbuf(offset_s), sndlths(p), stypes(p), &
                            p, tag, comm, sndids(istep), ier )
            call CheckMPIReturn(subName,ier)
         endif

         if (istep > maxreqh) then

            ! Wait for oldest irecv request to complete
            p = swapids(istep-maxreqh)
            if (rcvlths(p) > 0) then
               call mpi_wait( rcvids(istep-maxreqh), status, ier )
               call CheckMPIReturn(subName,ier)
            endif

            ! Submit a new irecv request
            if (rstep < steps) then
               rstep = rstep + 1
               p = swapids(rstep)
               if (rcvlths(p) > 0) then
                  tag = p + offset_t

                  offset_r = rdispls(p)+1
                  call mpi_irecv( rcvbuf(offset_r), rcvlths(p), rtypes(p), &
                                  p, tag, comm, rcvids(rstep), ier )
                  call CheckMPIReturn(subName,ier)
               endif
            endif

            ! Wait for outstanding i(r)send request to complete
            p = swapids(istep-maxreqh)
            if (sndlths(p) > 0) then
               call mpi_wait( sndids(istep-maxreqh), status, ier )
               call CheckMPIReturn(subName,ier)
            endif

         endif

      enddo

      ! wait for rest of send and receive requests to complete
      do istep=steps-maxreqh+1,steps
         p = swapids(istep)
         if (rcvlths(p) > 0) then
            call mpi_wait( rcvids(istep), status, ier )
            call CheckMPIReturn(subName,ier)
         endif
         if (sndlths(p) > 0) then
            call mpi_wait( sndids(istep), status, ier )
            call CheckMPIReturn(subName,ier)
         endif
      enddo

   endif

#endif

   return

   end subroutine pio_swapm_{TYPE}

!
!========================================================================
!
! TYPE int,real,double,long
   subroutine pio_N2M_{TYPE} ( &
      num_nprocs, my_ntask, num_mprocs, mprocs,    &
      sndbuf, sbuf_siz, sndlths, sdispls, stypes,  &
      rcvbuf, rbuf_siz, rcvlths, rdispls, rtypes,  &
      comm )

!-----------------------------------------------------------------------
!
!> Purpose:
!!   Specialized N-to-M gather communication operator that also
!!   includes the communication pattern used in corresponding
!!   M-to-N scatter communication operator.
!!   Motivated by high MPI overhead incurred on some systems the
!!   first time that two processes communicate. This implementation
!!   has demonstrated less overhead than implementations that are more
!!   efficient without the MPI startup overhead.
!!
!! Author: P. Worley, September 2017
!<
!-----------------------------------------------------------------------
#ifdef TIMING
  use perf_mod, only : t_startf, t_stopf   ! _EXTERNAL
#endif
!-----------------------------------------------------------------------
   implicit none
!---------------------------Input arguments--------------------------
!
   integer, intent(in) :: num_nprocs             ! size of communicator
   integer, intent(in) :: my_ntask               ! MPI task id with communicator
   integer, intent(in) :: num_mprocs             ! number of 'M' tasks
   integer, intent(in) :: mprocs(0:num_mprocs-1) ! MPI task ids for 'M' tasks
   integer, intent(in) :: sbuf_siz               ! size of send buffer
   integer, intent(in) :: rbuf_siz               ! size of receive buffer

   integer, intent(in) :: sndlths(0:num_nprocs-1)! length of outgoing message
   integer, intent(in) :: sdispls(0:num_nprocs-1)! offset from beginning of send
                                                 !  buffer where outgoing messages
                                                 !  should be sent from
   integer, intent(in) :: stypes(0:num_nprocs-1) ! MPI data types
   integer, intent(in) :: rcvlths(0:num_nprocs-1)! length of incoming messages
   integer, intent(in) :: rdispls(0:num_nprocs-1)! offset from beginning of receive
                                                 !  buffer where incoming messages
                                                 !  should be placed
   integer, intent(in) :: rtypes(0:num_nprocs-1) ! MPI data types
   {VTYPE}, intent(in) :: sndbuf(sbuf_siz)       ! outgoing message buffer

   integer, intent(in) :: comm                   ! MPI communicator

!---------------------------Output arguments--------------------------
!
   {VTYPE}, intent(out)  :: rcvbuf(rbuf_siz)     ! incoming message buffer

#ifndef _MPISERIAL
!
!---------------------------Local workspace-------------------------------------------
!
   character(len=*), parameter :: subName=modName//'::pio_N2M_{TYPE}'

   logical :: IsMTask(0:num_nprocs-1)            ! Is an 'N' task and 'M' task?

   integer :: steps                              ! number of swaps to initiate
   integer :: swapids(num_mprocs)                ! MPI task id of swap partners
   integer :: my_mtask                           ! index into mprocs if an 'M' task
   integer :: mp, np                             ! task indices
   integer :: istep                              ! loop index
   integer :: tag                                ! MPI message tag
   integer :: offset_t                           ! MPI message tag offset, for addressing
                                                 !  message conflict bug (if necessary)
   integer :: offset_s                           ! index of message beginning in
                                                 !  send buffer
   integer :: offset_r                           ! index of message beginning in
                                                 !  receive buffer
   integer :: stride                             ! number of 'N' tasks to communicate with
                                                 !  each 'M' task during 'N-to-M' phase
   integer :: mp_start, np_start, np_stop        ! start/stop indices for processing
                                                 !  subsets of 'N' tasks
   integer :: subset_start, subset_stop          ! indices for processing subsets of
                                                 !  'N' tasks

   integer :: rcvid                              ! receive request ids
   integer :: ier                                ! return error status
   integer :: status(MPI_STATUS_SIZE)            ! MPI status
!
!-------------------------------------------------------------------------------------
!
#ifdef _NO_PIO_SWAPM_TAG_OFFSET
   offset_t = 0
#else
   offset_t = num_nprocs
#endif
!
   ! if necessary, send to self
   if (sndlths(my_ntask) > 0) then
      tag = my_ntask + offset_t

      offset_r = rdispls(my_ntask)+1
      call mpi_irecv( rcvbuf(offset_r), rcvlths(my_ntask), rtypes(my_ntask), &
                      my_ntask, tag, comm, rcvid, ier )
      call CheckMPIReturn(subName,ier)

      offset_s = sdispls(my_ntask)+1
      call mpi_send( sndbuf(offset_s), sndlths(my_ntask), stypes(my_ntask), &
                     my_ntask, tag, comm, ier )
      call CheckMPIReturn(subName,ier)

      call mpi_wait( rcvid, status, ier )
      call CheckMPIReturn(subName,ier)
   endif

   ! Calculate IsMTask array (Is an 'N' task an 'M' task?)
   ! Also determine whether my_ntask is an 'M' task and, 
   ! if so, which one it is.
   IsMTask(:) = .false.
   my_mtask = -1
   do mp=0,num_mprocs-1
      if (my_ntask .eq. mprocs(mp)) then
         my_mtask = mp
      endif
      IsMTask(mprocs(mp)) = .true.
   enddo

   ! M-to-M exchange between 'M' tasks
   if (my_mtask > -1) then

      ! calculate swap partners and communication ordering
      steps = 0
      do istep=1,ceil2(num_mprocs)-1
         mp = pair(num_mprocs,istep,my_mtask)
         if (mp >= 0) then
            np = mprocs(mp)
            if (sndlths(np) > 0 .or. rcvlths(np) > 0) then
               steps = steps + 1
               swapids(steps) = np
            end if
         end if
      end do

      ! all-to-all between 'M' tasks using point-to-point commands
      do istep=1,steps
         np = swapids(istep)
         call mpi_sendrecv (sndbuf(sdispls(np)+1), sndlths(np), &
                            stypes(np), np, my_ntask + offset_t,&
                            rcvbuf(rdispls(np)+1), rcvlths(np), &
                            rtypes(np), np, np + offset_t,      &
                            comm, status, ier)
         call CheckMPIReturn(subName,ier)
      end do

   endif

!
!gather/scatter between 'M' tasks and 'N' tasks, in groups of N/M
! processes
!
   stride = num_nprocs/num_mprocs
   if (my_mtask > -1) then

      np_start = my_mtask*stride
      np_stop  = (num_mprocs-1)*stride

      do subset_start=np_start,0,-stride

         if (subset_start < np_stop) then
            subset_stop = subset_start+stride-1
         else
            subset_stop = num_nprocs-1
         endif

         do np=subset_start,subset_stop,1
            if (.not. IsMTask(np)) then
               if (sndlths(np) > 0 .or. rcvlths(np) > 0) then
                  call mpi_send (sndbuf(sdispls(np)+1), sndlths(np),  &
                                 stypes(np), np, my_ntask + offset_t, &
                                 comm, status, ier                    )
                  call mpi_recv (rcvbuf(rdispls(np)+1), rcvlths(np),  &
                                 rtypes(np), np, np + offset_t,       &
                                 comm, status, ier                    )
               endif
            endif
         enddo

      enddo

      do subset_start=np_stop,np_start+1,-stride

         if (subset_start < np_stop) then
            subset_stop = subset_start+stride-1
         else
            subset_stop = num_nprocs-1
         endif

         do np=subset_start,subset_stop,1
            if (.not. IsMTask(np)) then
               if (sndlths(np) > 0 .or. rcvlths(np) > 0) then
                  call mpi_send (sndbuf(sdispls(np)+1), sndlths(np),  &
                                 stypes(np), np, my_ntask + offset_t, &
                                 comm, status, ier                    )
                  call mpi_recv (rcvbuf(rdispls(np)+1), rcvlths(np),  &
                                 rtypes(np), np, np + offset_t,       &
                                 comm, status, ier                    )
               endif
            endif
         enddo

      enddo

   else

      mp_start = my_ntask/stride

      do mp=mp_start, num_mprocs-1
         np = mprocs(mp)
         if (sndlths(np) > 0 .or. rcvlths(np) > 0) then
            call mpi_recv (rcvbuf(rdispls(np)+1), rcvlths(np),  &
                           rtypes(np), np, np + offset_t,       &
                           comm, status, ier                    )

            call mpi_send (sndbuf(sdispls(np)+1), sndlths(np),  &
                           stypes(np), np, my_ntask + offset_t, &
                           comm, status, ier                    )
         endif
      enddo

      do mp=0, mp_start-1
         np = mprocs(mp)
         if (sndlths(np) > 0 .or. rcvlths(np) > 0) then
            call mpi_recv (rcvbuf(rdispls(np)+1), rcvlths(np),  &
                           rtypes(np), np, np + offset_t,       &
                           comm, status, ier                    )

            call mpi_send (sndbuf(sdispls(np)+1), sndlths(np),  &
                           stypes(np), np, my_ntask + offset_t, &
                           comm, status, ier                    )
         endif
      enddo

   endif

#endif

   return

   end subroutine pio_N2M_{TYPE}
!
!========================================================================
!



end module pio_spmd_utils
